{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\anaconda3\\envs\\nanodet\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Global seed set to 1234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1234"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nanodet.data.collate import naive_collate\n",
    "from nanodet.data.dataset import build_dataset\n",
    "from nanodet.evaluator import build_evaluator\n",
    "from nanodet.trainer.task import TrainingTask\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from nanodet.util import (\n",
    "    NanoDetLightningLogger,\n",
    "    cfg,\n",
    "    convert_old_model,\n",
    "    env_utils,\n",
    "    load_config,\n",
    "    load_model_weight,\n",
    "    mkdir,\n",
    ")\n",
    "\n",
    "#Set logger and seed\n",
    "logger = NanoDetLightningLogger('test')\n",
    "pl.seed_everything(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create the task configuration file required for training\n",
    "def create_exp_cfg(yml_path, task):\n",
    "    all_names = [\"aereoplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "    #Load the YAML file\n",
    "    with open(yml_path, 'r') as file:\n",
    "        temp_cfg = yaml.safe_load(file)\n",
    "    #Save dir of the model\n",
    "    temp_cfg['save_dir'] = 'models/task' + str(task)\n",
    "    #If base task, training and testing classes are the same\n",
    "    if task == 0:\n",
    "        temp_cfg['data']['train']['class_names'] = all_names[:15]\n",
    "        temp_cfg['data']['val']['class_names'] = all_names[:15]\n",
    "        temp_cfg['model']['arch']['head']['num_classes'] = 15\n",
    "        temp_cfg['model']['arch']['aux_head']['num_classes'] = 15\n",
    "    #Else, training only on task specific class, and testing on all classes\n",
    "    else:\n",
    "        temp_cfg['data']['train']['class_names'] = [all_names[14+task]]\n",
    "        temp_cfg['data']['val']['class_names'] = all_names[:15+task]\n",
    "        temp_cfg['model']['arch']['head']['num_classes'] = 15+task\n",
    "        temp_cfg['model']['arch']['aux_head']['num_classes'] = 15+task\n",
    "        temp_cfg['schedule']['load_model'] = 'models/task' + str(task-1) + '/model_best.ckpt'\n",
    "    temp_cfg_name = 'cfg/task' + str(task) + '.yml'\n",
    "    print(temp_cfg)\n",
    "    #Save the new configuration file\n",
    "    with open(temp_cfg_name, 'w') as file:\n",
    "        yaml.safe_dump(temp_cfg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:40:28]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mStarting task0\u001b[0m\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:40:28]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mStarting task0\u001b[0m\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:40:28]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mSetting up data...\u001b[0m\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:40:28]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mSetting up data...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'save_dir': 'models/task0', 'model': {'weight_averager': {'name': 'ExpMovingAverager', 'decay': 0.9998}, 'arch': {'name': 'NanoDetPlus', 'detach_epoch': 10, 'backbone': {'name': 'ShuffleNetV2', 'model_size': '1.0x', 'out_stages': [2, 3, 4], 'activation': 'LeakyReLU'}, 'fpn': {'name': 'GhostPAN', 'in_channels': [116, 232, 464], 'out_channels': 96, 'kernel_size': 5, 'num_extra_level': 1, 'use_depthwise': True, 'activation': 'LeakyReLU'}, 'head': {'name': 'NanoDetPlusHead', 'num_classes': 15, 'input_channel': 96, 'feat_channels': 96, 'stacked_convs': 2, 'kernel_size': 5, 'strides': [8, 16, 32, 64], 'activation': 'LeakyReLU', 'reg_max': 7, 'norm_cfg': {'type': 'BN'}, 'loss': {'loss_qfl': {'name': 'QualityFocalLoss', 'use_sigmoid': True, 'beta': 2.0, 'loss_weight': 1.0}, 'loss_dfl': {'name': 'DistributionFocalLoss', 'loss_weight': 0.25}, 'loss_bbox': {'name': 'GIoULoss', 'loss_weight': 2.0}}}, 'aux_head': {'name': 'SimpleConvHead', 'num_classes': 15, 'input_channel': 192, 'feat_channels': 192, 'stacked_convs': 4, 'strides': [8, 16, 32, 64], 'activation': 'LeakyReLU', 'reg_max': 7}}}, 'class_names': ['aereoplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person'], 'data': {'train': {'name': 'XMLDataset', 'class_names': ['aereoplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person'], 'img_path': 'C:/Dataset/VOC/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages', 'ann_path': 'C:/Dataset/VOC/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/annotations', 'input_size': [320, 320], 'keep_ratio': True, 'pipeline': {'perspective': 0.0, 'scale': [0.6, 1.4], 'stretch': [[1, 1], [1, 1]], 'rotation': 0, 'shear': 0, 'translate': 0.2, 'flip': 0.5, 'brightness': 0.2, 'contrast': [0.8, 1.2], 'saturation': [0.8, 1.2], 'normalize': [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]}}, 'val': {'name': 'XMLDataset', 'class_names': ['aereoplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person'], 'img_path': 'C:/Dataset/VOC/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages', 'ann_path': 'C:/Dataset/VOC/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/annotations', 'input_size': [320, 320], 'keep_ratio': True, 'pipeline': {'normalize': [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]}}}, 'device': {'gpu_ids': -1, 'workers_per_gpu': 4, 'batchsize_per_gpu': 16, 'precision': 32}, 'schedule': {'optimizer': {'name': 'AdamW', 'lr': 0.001, 'weight_decay': 0.05}, 'warmup': {'name': 'linear', 'steps': 500, 'ratio': 0.0001}, 'total_epochs': 100, 'lr_schedule': {'name': 'CosineAnnealingLR', 'T_max': 300, 'eta_min': 5e-05}, 'val_intervals': 10}, 'grad_clip': 35, 'evaluator': {'name': 'CocoDetectionEvaluator', 'save_key': 'mAP'}, 'log': {'interval': 10}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:WARNING! Keeping only annotations of these categories [{'supercategory': 'aereoplane', 'id': 1, 'name': 'aereoplane'}, {'supercategory': 'bicycle', 'id': 2, 'name': 'bicycle'}, {'supercategory': 'bird', 'id': 3, 'name': 'bird'}, {'supercategory': 'boat', 'id': 4, 'name': 'boat'}, {'supercategory': 'bottle', 'id': 5, 'name': 'bottle'}, {'supercategory': 'bus', 'id': 6, 'name': 'bus'}, {'supercategory': 'car', 'id': 7, 'name': 'car'}, {'supercategory': 'cat', 'id': 8, 'name': 'cat'}, {'supercategory': 'chair', 'id': 9, 'name': 'chair'}, {'supercategory': 'cow', 'id': 10, 'name': 'cow'}, {'supercategory': 'diningtable', 'id': 11, 'name': 'diningtable'}, {'supercategory': 'dog', 'id': 12, 'name': 'dog'}, {'supercategory': 'horse', 'id': 13, 'name': 'horse'}, {'supercategory': 'motorbike', 'id': 14, 'name': 'motorbike'}, {'supercategory': 'person', 'id': 15, 'name': 'person'}]! \n",
      "WARNING:root:WARNING! Keeping only annotations of these categories [{'supercategory': 'aereoplane', 'id': 1, 'name': 'aereoplane'}, {'supercategory': 'bicycle', 'id': 2, 'name': 'bicycle'}, {'supercategory': 'bird', 'id': 3, 'name': 'bird'}, {'supercategory': 'boat', 'id': 4, 'name': 'boat'}, {'supercategory': 'bottle', 'id': 5, 'name': 'bottle'}, {'supercategory': 'bus', 'id': 6, 'name': 'bus'}, {'supercategory': 'car', 'id': 7, 'name': 'car'}, {'supercategory': 'cat', 'id': 8, 'name': 'cat'}, {'supercategory': 'chair', 'id': 9, 'name': 'chair'}, {'supercategory': 'cow', 'id': 10, 'name': 'cow'}, {'supercategory': 'diningtable', 'id': 11, 'name': 'diningtable'}, {'supercategory': 'dog', 'id': 12, 'name': 'dog'}, {'supercategory': 'horse', 'id': 13, 'name': 'horse'}, {'supercategory': 'motorbike', 'id': 14, 'name': 'motorbike'}, {'supercategory': 'person', 'id': 15, 'name': 'person'}]! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:41:54]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mCreating model...\u001b[0m\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:41:54]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mCreating model...\u001b[0m\n",
      "INFO:NanoDet:Creating model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "model size is  1.0x\n",
      "init weights...\n",
      "=> loading pretrained model https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\n",
      "Finish initialize NanoDet-Plus Head.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:41:54]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mUsing CPU training\u001b[0m\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:41:54]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mUsing CPU training\u001b[0m\n",
      "INFO:NanoDet:Using CPU training\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type        | Params\n",
      "------------------------------------------\n",
      "0 | model     | NanoDetPlus | 4.2 M \n",
      "1 | avg_model | NanoDetPlus | 4.2 M \n",
      "------------------------------------------\n",
      "8.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.4 M     Total params\n",
      "33.546    Total estimated model params size (MB)\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:41:54]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mWeight Averaging is enabled\u001b[0m\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:41:54]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mWeight Averaging is enabled\u001b[0m\n",
      "INFO:NanoDet:Weight Averaging is enabled\n",
      "c:\\Users\\franc\\anaconda3\\envs\\nanodet\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:42:35]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/100|Iter0(1/313)| mem:0G| lr:1.00e-07| loss_qfl:0.6333| loss_bbox:1.1477| loss_dfl:0.5212| aux_loss_qfl:0.6063| aux_loss_bbox:1.1129| aux_loss_dfl:0.5431| \u001b[0m\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:42:35]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/100|Iter0(1/313)| mem:0G| lr:1.00e-07| loss_qfl:0.6333| loss_bbox:1.1477| loss_dfl:0.5212| aux_loss_qfl:0.6063| aux_loss_bbox:1.1129| aux_loss_dfl:0.5431| \u001b[0m\n",
      "INFO:NanoDet:Train|Epoch1/100|Iter0(1/313)| mem:0G| lr:1.00e-07| loss_qfl:0.6333| loss_bbox:1.1477| loss_dfl:0.5212| aux_loss_qfl:0.6063| aux_loss_bbox:1.1129| aux_loss_dfl:0.5431| \n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:44:54]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/100|Iter10(11/313)| mem:0G| lr:2.01e-05| loss_qfl:0.6323| loss_bbox:1.1574| loss_dfl:0.5202| aux_loss_qfl:0.5481| aux_loss_bbox:1.1239| aux_loss_dfl:0.5148| \u001b[0m\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:44:54]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/100|Iter10(11/313)| mem:0G| lr:2.01e-05| loss_qfl:0.6323| loss_bbox:1.1574| loss_dfl:0.5202| aux_loss_qfl:0.5481| aux_loss_bbox:1.1239| aux_loss_dfl:0.5148| \u001b[0m\n",
      "INFO:NanoDet:Train|Epoch1/100|Iter10(11/313)| mem:0G| lr:2.01e-05| loss_qfl:0.6323| loss_bbox:1.1574| loss_dfl:0.5202| aux_loss_qfl:0.5481| aux_loss_bbox:1.1239| aux_loss_dfl:0.5148| \n",
      "c:\\Users\\franc\\anaconda3\\envs\\nanodet\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:45:07]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mStarting task1\u001b[0m\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:45:07]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mStarting task1\u001b[0m\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:45:07]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mStarting task1\u001b[0m\n",
      "INFO:NanoDet:Starting task1\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:45:07]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mSetting up data...\u001b[0m\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:45:07]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mSetting up data...\u001b[0m\n",
      "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[01-29 12:45:07]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mSetting up data...\u001b[0m\n",
      "INFO:NanoDet:Setting up data...\n",
      "WARNING:root:WARNING! Keeping only annotations of these categories [{'supercategory': 'pottedplant', 'id': 1, 'name': 'pottedplant'}]! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'save_dir': 'models/task1', 'model': {'weight_averager': {'name': 'ExpMovingAverager', 'decay': 0.9998}, 'arch': {'name': 'NanoDetPlus', 'detach_epoch': 10, 'backbone': {'name': 'ShuffleNetV2', 'model_size': '1.0x', 'out_stages': [2, 3, 4], 'activation': 'LeakyReLU'}, 'fpn': {'name': 'GhostPAN', 'in_channels': [116, 232, 464], 'out_channels': 96, 'kernel_size': 5, 'num_extra_level': 1, 'use_depthwise': True, 'activation': 'LeakyReLU'}, 'head': {'name': 'NanoDetPlusHead', 'num_classes': 16, 'input_channel': 96, 'feat_channels': 96, 'stacked_convs': 2, 'kernel_size': 5, 'strides': [8, 16, 32, 64], 'activation': 'LeakyReLU', 'reg_max': 7, 'norm_cfg': {'type': 'BN'}, 'loss': {'loss_qfl': {'name': 'QualityFocalLoss', 'use_sigmoid': True, 'beta': 2.0, 'loss_weight': 1.0}, 'loss_dfl': {'name': 'DistributionFocalLoss', 'loss_weight': 0.25}, 'loss_bbox': {'name': 'GIoULoss', 'loss_weight': 2.0}}}, 'aux_head': {'name': 'SimpleConvHead', 'num_classes': 16, 'input_channel': 192, 'feat_channels': 192, 'stacked_convs': 4, 'strides': [8, 16, 32, 64], 'activation': 'LeakyReLU', 'reg_max': 7}}}, 'class_names': ['aereoplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person'], 'data': {'train': {'name': 'XMLDataset', 'class_names': ['pottedplant'], 'img_path': 'C:/Dataset/VOC/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages', 'ann_path': 'C:/Dataset/VOC/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/annotations', 'input_size': [320, 320], 'keep_ratio': True, 'pipeline': {'perspective': 0.0, 'scale': [0.6, 1.4], 'stretch': [[1, 1], [1, 1]], 'rotation': 0, 'shear': 0, 'translate': 0.2, 'flip': 0.5, 'brightness': 0.2, 'contrast': [0.8, 1.2], 'saturation': [0.8, 1.2], 'normalize': [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]}}, 'val': {'name': 'XMLDataset', 'class_names': ['aereoplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant'], 'img_path': 'C:/Dataset/VOC/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages', 'ann_path': 'C:/Dataset/VOC/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/annotations', 'input_size': [320, 320], 'keep_ratio': True, 'pipeline': {'normalize': [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]}}}, 'device': {'gpu_ids': -1, 'workers_per_gpu': 4, 'batchsize_per_gpu': 16, 'precision': 32}, 'schedule': {'optimizer': {'name': 'AdamW', 'lr': 0.001, 'weight_decay': 0.05}, 'warmup': {'name': 'linear', 'steps': 500, 'ratio': 0.0001}, 'total_epochs': 100, 'lr_schedule': {'name': 'CosineAnnealingLR', 'T_max': 300, 'eta_min': 5e-05}, 'val_intervals': 10, 'load_model': 'models/task0/model_best.ckpt'}, 'grad_clip': 35, 'evaluator': {'name': 'CocoDetectionEvaluator', 'save_key': 'mAP'}, 'log': {'interval': 10}}\n"
     ]
    }
   ],
   "source": [
    "#Learning stream\n",
    "#task 0: train on first 15 classes, test on 15 classes\n",
    "#task 1: train on class n°16, test on 16 classes\n",
    "#task 2: train on class n°17, test on 17 classes\n",
    "#task 3: train on class n°18, test on 18 classes\n",
    "#task 4: train on class n°19, test on 19 classes\n",
    "#task 5: train on class n°20, test on 20 classes\n",
    "for task in range (0, 5):\n",
    "    logger = NanoDetLightningLogger('run_logs/task'+str(task))\n",
    "    logger.info(\"Starting task\" + str(task))\n",
    "    logger.info(\"Setting up data...\")\n",
    "    #Create the task configuration file based on the task number and load the configuration\n",
    "    create_exp_cfg('cfg/VOC.yml', task)\n",
    "    load_config(cfg, 'cfg/task' + str(task) + '.yml')\n",
    "    #Build datasets and dataloaders based on the task configuration file\n",
    "    train_dataset = build_dataset(cfg.data.train, \"train\")\n",
    "    val_dataset = build_dataset(cfg.data.val, \"test\")\n",
    "    evaluator = build_evaluator(cfg.evaluator, val_dataset)\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=cfg.device.batchsize_per_gpu,\n",
    "        shuffle=True,\n",
    "        num_workers=cfg.device.workers_per_gpu,\n",
    "        pin_memory=True,\n",
    "        collate_fn=naive_collate,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=cfg.device.batchsize_per_gpu,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.device.workers_per_gpu,\n",
    "        pin_memory=True,\n",
    "        collate_fn=naive_collate,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    #Create the model based on the task configuration file\n",
    "    logger.info(\"Creating model...\")\n",
    "    task = TrainingTask(cfg, evaluator)\n",
    "    #Load the model weights if task is not 0\n",
    "    if \"load_model\" in cfg.schedule:\n",
    "        ckpt = torch.load(cfg.schedule.load_model)\n",
    "        if \"pytorch-lightning_version\" not in ckpt:\n",
    "            warnings.warn(\n",
    "                \"Warning! Old .pth checkpoint is deprecated. \"\n",
    "                \"Convert the checkpoint with tools/convert_old_checkpoint.py \"\n",
    "            )\n",
    "            ckpt = convert_old_model(ckpt)\n",
    "        load_model_weight(task.model, ckpt, logger)\n",
    "        logger.info(\"Loaded model weight from {}\".format(cfg.schedule.load_model))\n",
    "    model_resume_path = (\n",
    "        os.path.join(cfg.save_dir, \"model_last.ckpt\")\n",
    "        if \"resume\" in cfg.schedule\n",
    "        else None\n",
    "    )\n",
    "    if cfg.device.gpu_ids == -1:\n",
    "        logger.info(\"Using CPU training\")\n",
    "        accelerator, devices, strategy, precision = (\n",
    "            \"cpu\",\n",
    "            None,\n",
    "            None,\n",
    "            cfg.device.precision,\n",
    "        )\n",
    "    else:\n",
    "        accelerator, devices, strategy, precision = (\n",
    "            \"gpu\",\n",
    "            cfg.device.gpu_ids,\n",
    "            None,\n",
    "            cfg.device.precision,\n",
    "        )\n",
    "\n",
    "    if devices and len(devices) > 1:\n",
    "        strategy = \"ddp\"\n",
    "        env_utils.set_multi_processing(distributed=True)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=cfg.save_dir,\n",
    "        max_epochs=cfg.schedule.total_epochs,\n",
    "        check_val_every_n_epoch=cfg.schedule.val_intervals,\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        log_every_n_steps=cfg.log.interval,\n",
    "        num_sanity_val_steps=0,\n",
    "        callbacks=[TQDMProgressBar(refresh_rate=0)],\n",
    "        logger=logger,\n",
    "        benchmark=cfg.get(\"cudnn_benchmark\", True),\n",
    "        gradient_clip_val=cfg.get(\"grad_clip\", 0.0),\n",
    "        strategy=strategy,\n",
    "        precision=precision,\n",
    "    )\n",
    "    trainer.fit(task, train_dataloader, val_dataloader, ckpt_path=model_resume_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanodet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
